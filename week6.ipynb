{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "530144c4",
   "metadata": {
    "id": "530144c4"
   },
   "source": [
    "<h1><center>  lab 7: Recurrent Neural Networks </center>\n",
    "    \n",
    "<img src=\"https://pbs.twimg.com/media/Dv7LCZFXcAM30kY?format=jpg&name=large\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c7066e",
   "metadata": {
    "id": "c3c7066e"
   },
   "source": [
    "```Created by Jinnie Shin (jinnie.shin@coe.ufl.edu)```\\\n",
    "```Date: June 14th 2022```\n",
    "\n",
    "```Image source: https://realpython.com/python-encodings-guide/g```\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQmNf86oJnfhpkPA9LnrFnAbfwF2VywPYpB_w&usqp=CAU\" align=\"left\" width=\"70\" height=\"70\" align=\"left\"> \n",
    "\n",
    " ### Required Packages or Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02eac3c7",
   "metadata": {
    "id": "02eac3c7"
   },
   "outputs": [],
   "source": [
    "#!pip install { } ! in case you run into the `package not avaialble` error\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe75acec",
   "metadata": {},
   "source": [
    "## Time-series or sequential prediction using Deep Learning \n",
    "<img src=\"https://www.researchgate.net/profile/Savvas-Varsamopoulos/publication/329362532/figure/fig4/AS:699592479895553@1543807253581/A-conceptual-visualization-of-the-recurrent-nature-of-an-RNN_W640.jpg\" width=\"500\">\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/b4sus.jpg\" width=\"700\">\n",
    "\n",
    "\n",
    "### Long Short Term Memory Network (LSTM) Architecture \n",
    "- Deep Learning and IRT (Yeung, 2019) \n",
    "- Rater-Bias, AES and IRT (Uto & Okano, 2021) \n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Xuan_Hien_Le2/publication/334268507/figure/fig8/AS:788364231987201@1564972088814/The-structure-of-the-Long-Short-Term-Memory-LSTM-neural-network-Reproduced-from-Yan_W640.jpg\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c901e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "            \n",
    "def get_callbacks(name_weights):\n",
    "    mcp_save = ModelCheckpoint(name_weights, monitor='val_auroc', \n",
    "                               verbose=0, save_best_only=True, mode='auto',\n",
    "                               save_weights_only=False, period=1)\n",
    "    return [mcp_save]\n",
    "\n",
    "def preprocess(df, target=True): # if your target is included in your dataframe ==True \n",
    "    data = df\n",
    "    data = data.fillna(0)\n",
    "    data = data.apply(pd.to_numeric)\n",
    "    X = data.drop(columns = ['Target'])\n",
    "    X = X.values\n",
    "    X_train = []\n",
    "    for i in range(len(X)):\n",
    "        X_train.append(np.reshape(X[i], (24, 1)))\n",
    "    X_train = np.asarray(X_train)\n",
    "    \n",
    "    if target == True:\n",
    "        y_train = data.Target\n",
    "        y_train = y_train.tolist()\n",
    "        y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    \n",
    "    else:\n",
    "        y_train = np.nan\n",
    "\n",
    "    return X_train,  y_train\n",
    "\n",
    "def model(HIDDEN_SIZE=10):\n",
    "    model1 = Sequential()\n",
    "    model1.add(LSTM(HIDDEN_SIZE, input_shape=(24, 1), unroll=True, return_sequences=True))\n",
    "    model1.add(LSTM(HIDDEN_SIZE, input_shape=(24, 1), unroll=True))\n",
    "    model1.add(Dense(1))\n",
    "    model1.add(Activation(\"sigmoid\"))\n",
    "   \n",
    "    return model1\n",
    "\n",
    "def train(X_train, y_train, k=4):\n",
    "    \n",
    "    BATCH_SIZE = 128\n",
    "    NUM_EPOCHS_PER_ITERATION=150 \n",
    "    \n",
    "    skf = StratifiedKFold(k, shuffle=True)\n",
    "    cvscores=[]\n",
    "    for n, (itrain, ival) in enumerate(skf.split(X_train, y_train)):\n",
    "        print('step %d of %d'%(n+1, skf.n_splits))\n",
    "        \n",
    "        name_weights = 'final_model_fold' +str(n)+ \"_weights.h5\"\n",
    "        callbacks = get_callbacks(name_weights =name_weights)\n",
    "        \n",
    "        \n",
    "        newModel = model()\n",
    "        newModel.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['acc'])\n",
    "        newModel.fit(X_train[itrain],y_train[itrain], \n",
    "                      batch_size=BATCH_SIZE, \n",
    "                      epochs=NUM_EPOCHS_PER_ITERATION, \n",
    "                      callbacks=callbacks, \n",
    "                      validation_data = (X_train[ival],y_train[ival]))\n",
    "        \n",
    "        \n",
    "        scores = newModel.evaluate(X_train[ival], y_train[ival])\n",
    "        print(\"%s: %.2f%%\" % (newModel.metrics_names[1], (scores[1]-0.5)*2))\n",
    "        cvscores.append((scores[1]-0.5)*2)\n",
    "    return cvscores \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634bc5ce",
   "metadata": {},
   "source": [
    "<img src=\"https://i.pinimg.com/736x/2e/aa/7d/2eaa7d5021ca7c3c98bc93b98b9646fe.jpg\" align=\"left\" width=\"70\" height=\"70\" align=\"left\">\n",
    "\n",
    "\n",
    "### Task 1: Constructing a deep-learning Model\n",
    "Predict whether the student have used the time efficient during the assessment.\n",
    ">Output: ‘Target’: Binary (0 or 1)\n",
    ">Input: Total time (seconds) that a student spend to solve a question \n",
    "\n",
    "> **STEP 1**: data import and split \n",
    ">> - let's call your dataset `df`, import `df` using `pandas`. It's in your `./week6/` foler. The data is called `data.xlsx`\n",
    ">> - Set your index column as 'STUDENTID'\n",
    ">> - HINT: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html\n",
    "\n",
    ">**STEP 2**: data preprocessing \n",
    ">> - preprocess your data for dimension changes using the function `preprocess`\n",
    ">> - call your output X_train and Y_train \n",
    ">> -  split your data so you can set aside the testset. `from sklearn.model_selection import train_test_split`(HINT: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    ">> - Set the test size == 0.1\n",
    "\n",
    ">**STEP 3**: load your model and plot to train \n",
    ">> - you can define your LSTM model as 'mymodel' using the functon 'model'\n",
    ">> - then plot your model using plot_model using `from keras.utils.vis_utils import plot_model` (HINT: `plot_model(model)`)\n",
    "\n",
    ">**STEP 4**: Model Training  \n",
    ">> - you can use the function `train`\n",
    "\n",
    ">**STEP 5**: check the model performance \n",
    ">> - compute the cohen_kappa_score and the accuracy of your classification/prediction results \n",
    ">> - HINT: `from sklearn.metrics import cohen_kappa_score`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91de1c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ your code here ################\n",
    "\n",
    "# step 1: data import and split \n",
    "import pandas as pd  \n",
    "\n",
    "# let's call your dataset df, import df using pandas \n",
    "# Set your index column as 'STUDENTID'\n",
    "# HINT: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html\n",
    "\n",
    "\n",
    "\n",
    "# preprocess your data for dimension changes using the function 'preprocess' in line 27.\n",
    "# call your output X_train and Y_train \n",
    "\n",
    "\n",
    "\n",
    "# step 2: split your data so you can set aside the testset. \n",
    "from sklearn.model_selection import train_test_split\n",
    "# HINT: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "\n",
    "# step 3: load your model and plot to train \n",
    "# you can define your LSTM model as 'mymodel' using the functon 'model' in line 48.\n",
    "\n",
    "\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "# then plot your model using plot_model\n",
    "# HINT: plot_model(model, to_file='model.png')\n",
    "\n",
    "#plot_model(model)#, to_file='model.png')\n",
    "\n",
    "# step 4: Model Training  \n",
    "# you can use the function 'train' in line 57\n",
    "\n",
    "\n",
    "# step 6: check the model performance \n",
    "\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a0924c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "week9.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
