{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "530144c4",
      "metadata": {
        "id": "530144c4"
      },
      "source": [
        "<h1><center>  Lab 2 : ML Overview: Supervised Learning algorithms </center>\n",
        "    \n",
        "<img src=\"https://i.pinimg.com/736x/02/66/bd/0266bd22348df67f4cf04ab83bf38e5a.jpg\" width=\"600\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3c7066e",
      "metadata": {
        "id": "c3c7066e"
      },
      "source": [
        "```Created by Jinnie Shin (jinnie.shin@coe.ufl.edu)```\\\n",
        "```Date: May 25th 2023```\n",
        "\n",
        "```Image source: https://i.pinimg.com/736x/02/66/bd/0266bd22348df67f4cf04ab83bf38e5a.jpg```\n",
        "\n",
        "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQmNf86oJnfhpkPA9LnrFnAbfwF2VywPYpB_w&usqp=CAU\" align=\"left\" width=\"70\" height=\"70\" align=\"left\"> \n",
        "\n",
        " ### Required Packages or Dependencies\n",
        " We learned how to download packages in python in our last lecture -- e.g., pip install `numpy`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "02eac3c7",
      "metadata": {
        "id": "02eac3c7"
      },
      "outputs": [],
      "source": [
        "#!pip install { } ! in case you run into the `package not avaialble` error\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "#import matplotlib.pyplot as plt ### ----- pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e8867d2",
      "metadata": {
        "id": "7e8867d2"
      },
      "source": [
        "## Data\n",
        "\n",
        "The data consisted of the labeled chats from an online collaborative problem-solving study (Hao et al., 2015). Each turn of the chats has been coded into **one of the four categories** of collaborative problem-solving skills (Link: https://repository.isls.org/bitstream/1/462/1/297.pdf)\n",
        "- *Macro level evience* - infer: Collaborative problem-solving skills\n",
        "\n",
        "#### Goal\n",
        "- To create an automated classifier using machine learning methods to label the chats automatically\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "13a38ab7",
      "metadata": {
        "id": "13a38ab7"
      },
      "outputs": [],
      "source": [
        "X=pd.read_csv('https://raw.githubusercontent.com/jinnieshinufl/EDF-6938-Computational-Psychometrics/main/2022/week3_data/chat_bigram_feature.csv.gz',compression='gzip').values\n",
        "y=pd.read_csv('https://raw.githubusercontent.com/jinnieshinufl/EDF-6938-Computational-Psychometrics/main/2022/week3_data/chat_label.csv').values.ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9abed1f3",
      "metadata": {
        "id": "9abed1f3",
        "outputId": "c87573ea-6569-41c5-8fc3-7e3638ffbc32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "X\n",
        "\n",
        "# inspect the dimension of the data \n",
        "###### Your code here ########\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "116c6dd5",
      "metadata": {
        "id": "116c6dd5"
      },
      "source": [
        "- Each turn of the chats is already converted into a numerical vector using a NLP vectorization approach (we will cover this in our NLP class :)) \n",
        "- So now one variable (or feature in CP) represents a uni-gram or a bi-gram token (e.g., \"I\", \"I-HAVE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9ebf4979",
      "metadata": {
        "id": "9ebf4979",
        "outputId": "a2f510ae-1b5c-4502-a37f-d096f7db2425",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 4, ..., 3, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "y # Let's take a look at the output data together \n",
        "\n",
        "# inspect the distribution of the output \n",
        "###### Your code here ########\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d47d8cb2",
      "metadata": {
        "id": "d47d8cb2"
      },
      "source": [
        "- Like we explained earlier, the output variable is the hand-coded categorization of one of the four collaborative problem-solving skills"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "677dd035",
      "metadata": {
        "id": "677dd035"
      },
      "source": [
        "<img src=\"https://i.pinimg.com/736x/2e/aa/7d/2eaa7d5021ca7c3c98bc93b98b9646fe.jpg\" align=\"left\" width=\"70\" height=\"70\" align=\"left\">\n",
        "\n",
        " ## Task 1: Training & Testing data \n",
        ">  **Q1.** In order to analyze large dataset efficiently, we will use the package `scikit-learn` to implement regression models. \n",
        ">> **Step 1**: Download the package `!pip install sklearn` \\ Let's try to use our `X` and `y` to investigate whether the chat can sufficiently predict the complexity of the CPS skills. In order to analyze large dataset efficiently, we will use the package `scikit-learn` to implement regression models. \n",
        ">\n",
        ">> **Step 2**: Import models ` from sklearn.linear_model import LinearRegression`\\\n",
        ">> **Step 3**: Call a new module `lr = LinearRegression()` \\\n",
        ">> **Step 4**: Fit the dataset using `lr.fit({input}, {output})` and check the intercept and the coefficients using `lr.intercept_` and `lr.coef_`\\\n",
        ">> **Step 5**: Using the model you fit in Step 3, let's predict the outcome and round it up using `pred = lr.predict(X)`\\\n",
        ">> **Step 6**: Let's evaluate the prediction accuracy. First import `from sklearn.metrics import accuracy_score, r2_score`\n",
        "and going back to your script `r2_score(pred, {output})` `accuracy_score(pred, {output})`\n",
        "\n",
        "> More information about the package is available at: https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares\n",
        "\n",
        "> Q4. Any problems with this evaluation scheme?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b7f0c1da",
      "metadata": {
        "id": "b7f0c1da",
        "outputId": "962f0ede-1255-4d32-d386-df41f2ae85a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the intercept value of my linear regression -------\n",
            "3.0292720158955744\n",
            "This is the coefficient value of my linear regression -------\n",
            "[ 2.46203553  0.09319471  0.96269967 ... -0.30449466 -0.73377929\n",
            " -0.35539082]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6403121561888905"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "################################### YOUR CODE HERE #############################\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "\n",
        "lr = LinearRegression() # model development \n",
        "\n",
        "lr.fit(X, y) #model learning \n",
        "\n",
        "pred = lr.predict(X)\n",
        "\n",
        "print('This is the intercept value of my linear regression -------')\n",
        "print(lr.intercept_)\n",
        "print('This is the coefficient value of my linear regression -------')\n",
        "print(lr.coef_)\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, r2_score \n",
        "\n",
        "r2_score(pred, y) # step4: model evaluation \n",
        "\n",
        "# What does your model evaluation mean? \n",
        "\n",
        "###############################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32f35a8c",
      "metadata": {
        "id": "32f35a8c"
      },
      "source": [
        "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66d8328b",
      "metadata": {
        "id": "66d8328b"
      },
      "source": [
        "### Problem setting 2\n",
        "> Let's classify the lables using the chat \n",
        "\n",
        "$\\rightarrow$ classify the lables using the chat. \n",
        "\n",
        "> We will implement and use the support vector classifer and neural networks model (what we covered in the previous lecture :)) ), as our main prediction. We will take a look at how the model weights are learned using **the gradient descent algorithms**. \n",
        "\n",
        "### We will first define a few models we learned so far... "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "85ec37ae",
      "metadata": {
        "id": "85ec37ae"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC # for Support Vector Machine\n",
        "model_SVM = LinearSVC()\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier #neural network \n",
        "nn = MLPClassifier()\n",
        "# let's take a look: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier #Random forest \n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier #GBM \n",
        "clf = GradientBoostingClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fc2b408",
      "metadata": {
        "id": "7fc2b408"
      },
      "source": [
        "> *Let's explore!*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd8ace03",
      "metadata": {
        "id": "dd8ace03",
        "outputId": "c93cf8d9-77bb-4021-9662-9ddeee931db3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration--- 1\n",
            "0.7215474583895637\n",
            "iteration--- 2\n",
            "0.6842105263157895\n",
            "iteration--- 3\n",
            "0.7125506072874493\n",
            "iteration--- 4\n",
            "0.7151215121512151\n",
            "iteration--- 5\n",
            "0.666966696669667\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC # for Support Vector Machine\n",
        "from sklearn.metrics import accuracy_score # metric\n",
        "from sklearn.model_selection import KFold  # evaluation scheme\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "i=0\n",
        "for train_index, test_index  in kf.split(X):\n",
        "    \n",
        "    X_train, X_test = X[train_index], X[test_index] #this is to find and define train-test-folds\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model_SVM = LinearSVC() #this is to define or develop a model \n",
        "    model_SVM.fit(X_train, y_train) #step 3 : model learning but only using the training set \n",
        "    pred = model_SVM.predict(X_test)\n",
        "    print('iteration---', i+1)\n",
        "    print(accuracy_score(pred, y_test)) # evaluation scheme (proportion of correct classification)\n",
        "    i+=1 \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55c646f8",
      "metadata": {
        "id": "55c646f8"
      },
      "outputs": [],
      "source": [
        "# Report the Average performance of SVM \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing the Results of SVM, NNs, GBM, and RF"
      ],
      "metadata": {
        "id": "mjUsoEbpmpFc"
      },
      "id": "mjUsoEbpmpFc"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC # for Support Vector Machine\n",
        "from sklearn.metrics import accuracy_score # metric\n",
        "from sklearn.model_selection import KFold  # evaluation scheme\n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "i=0\n",
        "for train_index, test_index  in kf.split(X):\n",
        "    \n",
        "    X_train, X_test = X[train_index], X[test_index] #this is to find and define train-test-folds\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    ######### your code here #########\n",
        "\n",
        "\n",
        "\n",
        "     #######################################\n",
        "    i+=1 \n",
        "    \n"
      ],
      "metadata": {
        "id": "3HrC6iGBmvEj"
      },
      "id": "3HrC6iGBmvEj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}